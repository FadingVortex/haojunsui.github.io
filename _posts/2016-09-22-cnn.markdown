---
layout:     post
title:      "Classifying Images using a Convolutional Neural Network"
subtitle:   "Convolutional Neural Network"
date:       2016-09-26 05:00:00
author:     "Haojun"
header-img: "img/in-post/cnn/header.jpg"
catalog:    true
tags:
    - Computer Vision
    - Convolutional Neural Network
    - Matlab
---

<script src='https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML'></script>

## Introduction

#### Task Performed

In this project we created a convolutional neural network and used it to classify the CIFAR-10 dataset. We created a convolutional neural network using eighteen layers, consisting of six layer types. The layer types were image normalization, convolution, rectified linear units, maxpool, fully connected, and softmax. In the following report, we describe each of these different layers types in detail. We also describe and show observations and results for the CNN, classifying the CIFAR-10 images using provided filters and bias values. Finally, we test our CNN on external images, found online, and present our findings. We hope to achieve a better understanding of convolutional neural networks and their implementation after completing this report. For this specific project, we wish to see that our network will have a good prediction rate accuracy.

## Layer Types & Description

#### Image Normalization

The first step in our convolutional neural network is to normalize the input image we are given. Images are normally given as a set of RGB values. These values range from 0 to 255 for each RGB channel. We then want to normalize all of these values to a range from -0.5 to 0.5. To do this we simply can take the input image and apply the following transformation on it:

$$Out(i,j,k)=\frac{In(i,j,k)}{255.0}-0.5$$

For example, let’s say we were given an image pixel with the following values, (R, G, B) = (10, 128, 20). Let us apply this image normalization technique to see what we get. So we will have (10, 128, 20)/255.0 − 0.5, which gives us (−0.4608,0.0020,−0.4216) as our normalized values. As we can see all the values are are between -0.5 and 0.5. Also, notice that the G value was 128 which is nearly half of 255 and as a result we get a value very close to zero after normalization. We can now used this normalized value in the rest of our convolutional neural network. Normalization of data is a necessary and useful technique in most machine learning applications. In MATLAB, this step can be easily implemented and follows exactly from the transformation we have just described. We will just take in the input array and divide by 255 and subtract by 0.5.

#### Rectified Linear Unit
We use rectified linear units (\texttt{ReLU}s) to threshold the input. These are usually the next layer after convolutions in convolutional neural networks.  We define \texttt{ReLU}s the following way:$$Out(i,j,k)=max(In(i,j,k),0)$$
\par So for any input we are given, we will make sure the output always has values 0 or greater. We will demonstrate this technique by showing you an example on a matrix. We have our original matrix, $A$, defined as follows:
